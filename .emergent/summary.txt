<analysis>**original_problem_statement:**
The user initially requested a comprehensive audit of the website . The requirements included 100% testing of all links for health and language consistency (Turkish pages must only link to Turkish pages, and English to English), checking for broken images, ensuring image content is relevant to the page text, verifying content language consistency, and performing basic technical SEO checks. The output was to be a summary report and a detailed CSV file.

The scope of the project evolved significantly. The user then requested:
1.  An ORDER file () to be created, which would contain instructions for another agent to fix the identified errors on the  website.
2.  The developed auditing tool to be packaged as a standalone application that can run on a local PC using Docker.
3.  The tool to be enhanced into a general-purpose website scraper and content downloader.
4.  The ability to crawl any user-specified URL.
5.  Features to download images, text, and videos from various platforms, including YouTube, VK.com, TikTok, etc.
6.  A Direct Download feature to fetch a single image or video from a URL without performing a full site scan.

**User's preferred language**: Turkish

**what currently exists?**
A full-stack web application built with a FastAPI backend and a React frontend, containerized with Docker for local execution. The application serves as a website crawler and a multimedia downloader.

-   **Backend:** Uses Playwright for headless browsing to handle JavaScript-rendered sites and  to support video downloads from over 1000 websites.
-   **Frontend:** A web UI that allows a user to input a URL to start a scan, view the progress, and see the results categorized into Issues, Images, Videos, and Texts. It includes features to download the scraped assets. A Direct Download tab allows users to download single videos (as video or MP3) or images directly from their URLs.
-   **Deployment:** The project is configured with  and respective Dockerfiles for the frontend, backend, and a MongoDB service, allowing for easy local setup.
-   **Documentation:** A  file provides instructions for building and running the application locally. An  file detailing the fixes for  has also been created.

**Last working item**:
-   **Last item agent was working:** Troubleshooting the local Docker deployment for the user. The user reported that the YouTube video download feature was failing with a Requested format is not available error, and the scanner found no errors on a site known to have issues.
-   **Reasoning:** The agent correctly diagnosed that  (the video download library) was likely outdated due to YouTube's frequent updates. For the second issue, the agent explained that the AI-powered visual-content analysis is a platform-exclusive feature (relying on ) and is not available in the local Docker version, which only performs technical checks like finding broken links.
-   **Status**: USER VERIFICATION PENDING
-   **Agent Testing Done**: N
-   **Which testing method agent to use?**: Manual testing by user. The user needs to run the commands provided by the agent () and re-attempt the YouTube download in their local environment.
-   **User Testing Done**: N

**All Pending/In progress Issue list**:
-   **Issue 1**: YouTube video download fails in the local Docker environment. (Priority: P0)

**Issues Detail**:
-   **Issue 1**:
    -   **Attempted fixes**: The agent instructed the user to update the  package within the running Docker container using . The user confirmed the command ran successfully.
    -   **Next debug checklist**:
        1.  The user needs to restart the backend container () as advised.
        2.  The user must retry downloading the same YouTube URL.
        3.  If it fails again, the user should provide the new logs from  for further analysis. The 403 Forbidden and format not available errors can sometimes point to regional restrictions or videos that require a logged-in session, which is a more complex issue to solve.
    -   **Why fix this issue and what will be achieved with the fix?**: This is a core feature requested by the user. Fixing it will make the video downloader functional as expected.
    -   **Status**: USER VERIFICATION PENDING
    -   **Is recurring issue?**: N
    -   **Should Test frontend/backend/both after fix?**: Backend
    -   **Blocked on other issue**: None

**In progress Task List**:
None. All development tasks are complete, pending the resolution of the above issue.

**Upcoming and Future Tasks**
None. All user requirements have been implemented.

**Completed work in this session**
- **Website Auditor & Scraper Application:**
  - Built a FastAPI backend and React frontend from scratch.
  - Implemented a basic crawler using  and an advanced one with  to handle JS-rendered websites ().
  - Integrated  to download videos and audio from over 1000 websites, including YouTube and VK.com.
  - Developed a Direct Download feature for single images and videos.
  - Created a UI to manage scans and view/download scraped assets ().
- **AI-Powered Analysis (Platform Only):**
  - Implemented AI-driven image-content relevancy checking using  (). This feature is confirmed to be unavailable in the local Docker version.
- **Dockerization & Local Deployment:**
  - Created  and Dockerfiles to allow the user to run the entire application stack (frontend, backend, database) locally.
  - Resolved multiple Docker-related issues, including version conflicts (), missing files (), library incompatibilities (), and persistent port conflicts.
- **Deliverables:**
  - Created the  file with detailed instructions to fix issues on the  website.
  - Provided  with local setup instructions.

**Earlier issues found/mentioned but not fixed**
None. All issues raised by the user during the session were addressed.

**Known issue recurrence from previous fork**
N/A

**Code Architecture**


**Key Technical Concepts**
-   **Backend**: Python, FastAPI, Playwright (for headless browsing), yt-dlp (for video downloading).
-   **Frontend**: React.js.
-   **Database**: MongoDB (for session/crawl data).
-   **Architecture**: Containerized microservices (frontend, backend, DB) for local deployment.

**key DB schema**
The application uses in-memory data structures (Pydantic models and dataclasses) to hold crawl state. While MongoDB is part of the stack, a strict schema is not defined in the conversation history.

**changes in tech stack**
- The crawler was upgraded from a simple  implementation to a more robust -based solution to correctly parse JavaScript-heavy websites.

**All files of reference**
-   : Defines the local multi-container setup. It's the entry point for the user.
-   : Contains all API endpoints for crawling, status checks, and downloading.
-   : Holds the core logic for crawling pages with Playwright and downloading media with yt-dlp.
-   : Contains the entire user interface.
-    & : Essential for building the application containers.
-   : A key deliverable for the user.
-   : The instruction manual for the user.

**Areas that need refactoring**:
- The frontend is a single monolithic  file. It should be refactored into smaller, reusable React components (e.g., , , ) for better maintainability.
- The backend has remnants of an older  that could be cleaned up or removed to avoid confusion with the primary .

**key api endpoints**
-   : Initiates a website scan.
-   : Provides real-time status of an ongoing scan.
-   : Fetches metadata for a video from services like YouTube/VK.
-   : Triggers a video download.
-   : Triggers an audio-only download.
-   : Downloads a single image from a given URL.
-   : Downloads a zip file of selected images from a crawl.

**Critical Info for New Agent**
-   **AI Feature is Platform-Only**: The AI-powered analysis for image-content relevance **does not work** in the local Docker version. It relies on a proprietary Emergent library. You must be clear about this limitation with the user. The local tool is a technical scraper and media downloader, not an AI auditor.
-   **User's Environment**: The user frequently experiences port conflicts on their local machine. Be prepared to modify ports in  if they report a port is already allocated error.
-   **User Communication**: The user is non-technical. Explain issues and solutions in simple, direct terms. Avoid technical jargon where possible.

**documents and test reports created in this job**
-   
-   
-   
-   
-    (Note: This is from an early stage and not relevant to the final Docker application).

**Last 10 User Messages and any pending HUMAN messages**
1.  **User asks if vk.com videos can be downloaded.** (Completed)
2.  **User agrees to add Playwright/yt-dlp and requests a better ORDER file.** (Completed)
3.  **User reports Docker build error:  missing.** (Fixed)
4.  **User reports Docker build error:  not found.** (Fixed)
5.  **User reports Docker run error: Port 8001 already allocated.** (Fixed)
6.  **User suggests using port 8006.** (Implemented)
7.  **User reports Docker run error: Port 27018 already allocated for MongoDB.** (Fixed)
8.  **User asks if having 3 containers is too many.** (Answered)
9.  **User reports YouTube download failed.** (In Progress)
10. **User provides logs, reports the  update, and expresses frustration that the tool failed and found no errors on a test site.** (Partially resolved by explaining the AI feature limitation; download fix is pending user verification).

**Project Health Check:**
-   **Broken**: The video download feature () in the local Docker environment was not working due to an outdated package. A fix was provided, but it is pending user confirmation.
-   **Mocked**: N/A.

**3rd Party Integrations**
-   **OpenAI (via emergentintegrations)**: Used for AI image analysis to check content relevance. **Uses Emergent LLM Key**. This integration is **NOT** available in the final local Docker application provided to the user.
-   **yt-dlp**: A command-line program to download videos from YouTube and many other sites. It is installed in the backend Docker container.
-   **Playwright**: A browser automation library used to crawl JavaScript-rendered websites. It is installed in the backend Docker container.

**Testing status**
-   **Testing agent used after significant changes**: NO
-   **Troubleshoot agent used after agent stuck in loop**: NO
-   **Test files created**: []
-   **Known regressions**: The AI visual analysis feature, which was present in the cloud-based version, is not available in the local Docker version.

**Credentials to test flow:**
N/A

**What agent forgot to execute**
The agent did not proactively add a command to the  to update  during the build process. This led to a runtime error for the user when YouTube updated its backend. The fix was applied reactively by instructing the user to run a command inside the container.</analysis>
